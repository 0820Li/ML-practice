{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc8G3n8kgmaP"
   },
   "source": [
    "# Overview\n",
    "\n",
    "Welcome to the CIFAR Classification Challenge for 4ML3 - Machine Learning (Fall 2024)! This competition is part of your course assignment and challenges you to apply machine learning and computer vision techniques to accurately classify images in the CIFAR dataset. The CIFAR dataset includes 60,000 images across multiple categories, representing everyday objects like airplanes, cars, animals, and more.\n",
    "\n",
    "Your task is to develop a model that can accurately classify each image into its correct category. This challenge not only reinforces concepts from the course but also lets you benchmark your approach against classmates in a competitive setting.\n",
    "\n",
    "# Goal\n",
    "\n",
    "Achieve the highest classification accuracy on the CIFAR dataset to excel in this assignment and climb the leaderboard.\n",
    "\n",
    "# Why Participate?\n",
    "\n",
    "- Apply Course Knowledge: Use what you've learned in 4ML3 to tackle a real-world dataset.\n",
    "- Compete with Classmates: Test your model and ranking against peers.\n",
    "- Build Practical Skills: Gain hands-on experience in computer vision and model optimization.\n",
    "\n",
    "Ready to showcase your skills? Letâ€™s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY_nE09afr2n"
   },
   "source": [
    "#Dataset Description\n",
    "\n",
    "The CIFAR-100 dataset is a widely recognized benchmark for image classification tasks. It comprises 60,000 color images with a resolution of 32x32 pixels, evenly distributed across 100 unique classes. These classes cover a broad range of categories, including animals, vehicles, and everyday objects, offering diverse challenges for image recognition models.\n",
    "\n",
    "For more details and to download the dataset, visit the official CIFAR-100 website. The training set is publicly accessible and available for download for this competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu5Oyfb1hdk9"
   },
   "source": [
    "Fetch the CIFAR-100 Training Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_27Z1SHug8ov",
    "outputId": "2b185920-3bb3-431b-a63b-281137dcab0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Batch of images shape: torch.Size([64, 3, 32, 32])\n",
      "Batch of labels: tensor([ 7,  0, 78, 85, 15,  6, 60, 86, 98, 15, 98, 68, 92, 64, 14, 40, 97, 82,\n",
      "        16, 85, 95, 46, 71, 66, 24, 13, 66, 67, 50, 55, 75, 10, 38,  9, 56, 38,\n",
      "        31, 38, 77, 90, 69, 43, 12,  0, 77, 52, 86, 93, 98, 43, 25, 65, 11, 58,\n",
      "        52, 76, 73, 68, 15, 83, 71, 79, 12,  5])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the transformations for the dataset (you can modify this as needed)\n",
    "transform = transforms.Compose([\n",
    "    ###### Add your transformations here ########\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download the CIFAR-100 training dataset\n",
    "train_dataset = datasets.CIFAR100(\n",
    "    root='./CIFAR_Data',       # Change this path if needed\n",
    "    train=True,          # Set to True to download the training set\n",
    "    download=True,       # Set to True to download if not already downloaded\n",
    "    transform=transform  # Apply transformations\n",
    ")\n",
    "##### Hyper-parameters\n",
    "batch_size = 64 #\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,      # Batch size (you can modify this as needed)\n",
    "    shuffle=True        # Shuffle data for training\n",
    ")\n",
    "\n",
    "# Example: Accessing one batch of images and labels\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch of images shape: {images.shape}\")\n",
    "print(f\"Batch of labels: {labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxH0S6IaiPGv"
   },
   "source": [
    "# Retrieving Images from `test.csv`\n",
    "\n",
    "You can use this code to retrieve and display images from the test.csv file, allowing for quick visualization of samples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "s5DzZwJKiU3X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in CSV: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "csv_path = './CIFAR_Data/test.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Total samples in CSV: {len(df)}\")\n",
    "\n",
    "# Function to reverse the normalization\n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "# Select a few samples to display (e.g., first 5)\n",
    "num_samples = 5\n",
    "samples = df.sample(n=num_samples)  # Randomly select samples for diversity\n",
    "\n",
    "# Iterate through the selected samples and display images\n",
    "for index, row in samples.iterrows():\n",
    "    # Extract pixel data and convert to numpy array\n",
    "    pixel_data = row[[f'pixel_{i}' for i in range(1, 3073)]].values.astype(np.float32)\n",
    "\n",
    "    # Reshape to (3, 32, 32)\n",
    "    image = pixel_data.reshape(3, 32, 32)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    image_tensor = torch.tensor(image)\n",
    "\n",
    "    # Reverse the normalization\n",
    "    image_tensor = unnormalize(image_tensor, cifar100_mean, cifar100_std)\n",
    "\n",
    "    # Clip the values to [0, 1] range\n",
    "    image_tensor = torch.clamp(image_tensor, 0, 1)\n",
    "\n",
    "    # Convert to numpy array and transpose to (32, 32, 3) for plotting\n",
    "    image_np = image_tensor.numpy().transpose(1, 2, 0)\n",
    "\n",
    "    # Convert to PIL Image for better handling (optional)\n",
    "    image_pil = Image.fromarray((image_np * 255).astype(np.uint8))\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image_pil)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pAeJYOOigFU"
   },
   "source": [
    "# Submission Guidelines\n",
    "\n",
    "Follow these steps to prepare and submit your predictions:\n",
    "\n",
    "1. Train Your Model: Utilize the CIFAR-100 training dataset to develop your image classification model.\n",
    "2. Predict on Custom Test Set: Apply your trained model to the provided custom test set to generate predictions.\n",
    "3. Format Your Predictions: Create a CSV file with the following columns:\n",
    "  - ID: Matches each test imageâ€™s unique identifier.\n",
    "  - LABEL: Your modelâ€™s predicted class label (an integer between 0 and 99) for each image.\n",
    "4. Ensure Correct Format: Verify that your CSV file adheres strictly to the required format to prevent submission errors.\n",
    "5. Submit for Evaluation: Upload your correctly formatted CSV file for assessment.\n",
    "\n",
    "Refer to the provided sample_submission.csv to ensure your submission meets the required format specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huZHjOc_jDs7"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "The primary evaluation metric for this competition is accuracy. Your modelâ€™s accuracy score will be calculated based on the percentage of images correctly classified in the test set.\n",
    "\n",
    "## Calculation of Accuracy\n",
    "- Accuracy is calculated as follows:\n",
    "\n",
    "Accuracy=Number of Correct Predictions / Total Number of Predictions\n",
    "\n",
    "This score will determine your position on the leaderboard, where higher accuracy corresponds to a better rank. In the case of a tie, Kaggleâ€™s default tie-breaking rules will apply.\n",
    "\n",
    "Note: Your model should assign each test image to one of the 100 classes in the CIFAR-100 dataset. Ensure your predictions are as accurate as possible to maximize your score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15vQzduni5oe"
   },
   "source": [
    "# Submission File\n",
    "\n",
    "For each ID in the test set, you must predict the class label for each image. The submission .csv file should contain a header and be in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kf27qlE8i9Qg"
   },
   "outputs": [],
   "source": [
    "ID,LABEL\n",
    "1,42\n",
    "2,7\n",
    "3,15\n",
    "4,23\n",
    ".\n",
    ".\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOhjrCA5hJou"
   },
   "source": [
    "The CIFAR-100 dataset is a collection of 60,000 color images, each of size 32x32 pixels, divided into 100 distinct classes. These images are grouped into 20 superclasses, each containing 5 subcategories. The dataset is split into 50,000 training images and 10,000 test images, with 600 images per class.\n",
    "\n",
    "Each image is labeled with one of the 100 classes, which cover a variety of objects from animals to vehicles and everyday items. Below is a list of the 100 categories:\n",
    "\n",
    "## Superclasses and Their Subclasses:\n",
    "- Aquatic mammals: beaver, dolphin, otter, seal, whale\n",
    "- Fish: aquarium fish, flatfish, ray, shark, trout\n",
    "- Flowers: sunflower, tulip, rose, daisy, dandelion\n",
    "- Food containers: bottle, bowl, can, cup, plate\n",
    "- Fruit and vegetables: apple, orange, banana, pear, pineapple\n",
    "- Household electrical devices: clock, computer keyboard, lamp, telephone, television\n",
    "- Household furniture: bed, chair, couch, table, wardrobe\n",
    "- Insects: bee, beetle, butterfly, caterpillar, cockroach\n",
    "- Large carnivores: bear, leopard, lion, tiger, wolf\n",
    "- Large man-made outdoor things: bridge, castle, house, road, skyscraper\n",
    "- Large natural outdoor scenes: cloud, forest, mountain, plain, sea\n",
    "- Large omnivores and herbivores: camel, cattle, chimpanzee, elephant, kangaroo\n",
    "- Medium-sized mammals: fox, porcupine, possum, raccoon, skunk\n",
    "- Non-insect invertebrates: crab, lobster, snail, spider, worm\n",
    "- People: baby, boy, girl, man, woman\n",
    "Reptiles: crocodile, dinosaur, lizard, snake, turtle\n",
    "- Small mammals: hamster, mouse, rabbit, shrew, squirrel\n",
    "- Trees: maple, oak, palm, pine, willow\n",
    "- Vehicles 1: bicycle, bus, motorcycle, pickup truck, train\n",
    "- Vehicles 2: lawn mower, rocket, streetcar, tank, tractor\n",
    "\n",
    "The images in CIFAR-100 are diverse and challenging, making this dataset an ideal testbed for developing and evaluating machine learning models for image classification tasks.\n",
    "\n",
    "This code snippet creates a DataFrame that maps each CIFAR-100 label (0-99) to its corresponding class name. You can use it to quickly look up class names based on label numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "aOv4HMzyh1SC",
    "outputId": "1c483c35-4a57-4a5b-d975-6a057db767ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LABEL     Class Name\n",
      "0      0          apple\n",
      "1      1  aquarium_fish\n",
      "2      2           baby\n",
      "3      3           bear\n",
      "4      4         beaver\n"
     ]
    }
   ],
   "source": [
    "cifar100_label_names = [\n",
    "    \"apple\", \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\", \"beetle\", \"bicycle\", \"bottle\", \"bowl\", \"boy\", \"bridge\", \"bus\", \"butterfly\", \"camel\", \"can\", \"castle\", \"caterpillar\", \"cattle\", \"chair\", \"chimpanzee\", \"clock\", \"cloud\", \"cockroach\", \"couch\", \"crab\", \"crocodile\", \"cup\", \"dinosaur\", \"dolphin\", \"elephant\", \"flatfish\", \"forest\", \"fox\", \"girl\", \"hamster\", \"house\", \"kangaroo\", \"keyboard\", \"lamp\", \"lawn_mower\", \"leopard\", \"lion\", \"lizard\", \"lobster\", \"man\", \"maple_tree\", \"motorcycle\", \"mountain\", \"mouse\", \"mushroom\", \"oak_tree\", \"orange\", \"orchid\", \"otter\", \"palm_tree\", \"pear\", \"pickup_truck\", \"pine_tree\", \"plain\", \"plate\", \"poppy\", \"porcupine\", \"possum\", \"rabbit\", \"raccoon\", \"ray\", \"road\", \"rocket\", \"rose\", \"sea\", \"seal\", \"shark\", \"shrew\", \"skunk\", \"skyscraper\", \"snail\", \"snake\", \"spider\", \"squirrel\", \"streetcar\", \"sunflower\", \"sweet_pepper\", \"table\", \"tank\", \"telephone\", \"television\", \"tiger\", \"tractor\", \"train\", \"trout\", \"tulip\", \"turtle\", \"wardrobe\", \"whale\", \"willow_tree\", \"wolf\", \"woman\", \"worm\"\n",
    "]\n",
    "label_mapping_df = pd.DataFrame({\n",
    "    'LABEL': range(100),\n",
    "    'Class Name': cifar100_label_names\n",
    "})\n",
    "# Display the first few rows of the DataFrame\n",
    "print(label_mapping_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skxUyMJof3d8"
   },
   "source": [
    "# Custom Test Set\n",
    "\n",
    "Please note that our test set differs from the standard CIFAR-100 test set. We have provided a unique custom test set specifically for this competition. Your goal is to train your model using the original CIFAR-100 training data and predict labels for the images in our custom test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wkOvhB8f8Pw"
   },
   "source": [
    "# Understanding test.csv\n",
    "\n",
    "The test.csv file contains the data required for making predictions. Here's a breakdown of its structure:\n",
    "\n",
    "- ID: A unique identifier for each test image, used to align your predictions with the submission.\n",
    "- Image Data: Pixel values of each image, formatted for model processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJvGtsnzgO9-"
   },
   "source": [
    "# Steps to Use test.csv\n",
    "\n",
    "1. Exclude the ID Column: Remove the ID column before inputting the data into your model, as it is not part of the image features.\n",
    "2. Preprocess the Data: Apply any necessary preprocessing to match your modelâ€™s input requirements.\n",
    "3. Generate Predictions: Use your trained model to predict labels for the processed test data.\n",
    "\n",
    "After generating predictions, ensure your submission file (submission.csv) includes both the ID and LABEL columns, formatted according to the guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train You Model:\n",
    "\n",
    "Utilize the CIFAR-100 training dataset to develop your image classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/20, Loss: 4.110441615209555, Accuracy: 5.844%\n",
      "Train Epoch 2/20, Loss: 3.577148932935027, Accuracy: 13.806%\n",
      "Train Epoch 3/20, Loss: 3.227970868120413, Accuracy: 20.274%\n",
      "Train Epoch 4/20, Loss: 2.986966516355724, Accuracy: 24.778%\n",
      "Train Epoch 5/20, Loss: 2.797434077848254, Accuracy: 28.622%\n",
      "Train Epoch 6/20, Loss: 2.6448333338093573, Accuracy: 31.436%\n",
      "Train Epoch 7/20, Loss: 2.529741207656958, Accuracy: 34.042%\n",
      "Train Epoch 8/20, Loss: 2.415818886073959, Accuracy: 36.028%\n",
      "Train Epoch 9/20, Loss: 2.324403001066974, Accuracy: 37.924%\n",
      "Train Epoch 10/20, Loss: 2.2510025071366058, Accuracy: 39.468%\n",
      "Train Epoch 11/20, Loss: 2.181852614940585, Accuracy: 40.872%\n",
      "Train Epoch 12/20, Loss: 2.107633842684119, Accuracy: 42.752%\n",
      "Train Epoch 13/20, Loss: 2.0430637697124725, Accuracy: 44.03%\n",
      "Train Epoch 14/20, Loss: 2.0070960590296694, Accuracy: 44.688%\n",
      "Train Epoch 15/20, Loss: 1.9459495227355177, Accuracy: 46.116%\n",
      "Train Epoch 16/20, Loss: 1.8987676252794388, Accuracy: 47.196%\n",
      "Train Epoch 17/20, Loss: 1.8543247364061264, Accuracy: 48.15%\n",
      "Train Epoch 18/20, Loss: 1.8191024124469903, Accuracy: 48.966%\n",
      "Train Epoch 19/20, Loss: 1.7742656030313437, Accuracy: 49.77%\n",
      "Train Epoch 20/20, Loss: 1.7362341310666956, Accuracy: 50.836%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "'''\n",
    "Already have: \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CIFAR100_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR100_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CIFAR100_CNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs) \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        # calculate accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects += (preds == labels).sum().item() # if the prediction is correct\n",
    "        total += labels.size(0) # total number of labels\n",
    "\n",
    "    accuracy = 100 * corrects / total\n",
    "\n",
    "    \n",
    "    print(f'Train Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predict on Custom Test Set:\n",
    "\n",
    "Apply your trained model to the provided custom test set to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "'''\n",
    "Steps to use test.csv\n",
    "1. exclude the ID column\n",
    "2. preprocess the data, such as normalization and reshaping\n",
    "3. generate predictions, using the trained model to predict labels\n",
    "4. save the predictions to a CSV file\n",
    "5. format the CSV file to include the ID column\n",
    "'''\n",
    "# remove the ID column\n",
    "df_data= df.drop(columns=['ID'])\n",
    "\n",
    "'''\n",
    "transform= transforms.Compose([\n",
    "    ###### Add your transformations here ########\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])'''\n",
    "\n",
    "class PreProcess(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data.iloc[idx].values.astype(np.float32)\n",
    "        image = image.reshape(3, 32, 32)\n",
    "        # Convert to PIL Image\n",
    "        image = Image.fromarray(image.transpose(1, 2, 0).astype(np.uint8)) \n",
    "        # image = torch.tensor(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "test_dataset = PreProcess(df_data, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Generate predictions\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output_df = pd.DataFrame({'LABEL': predictions})\n",
    "# Format the CSV file to include the ID column\n",
    "output_df.insert(0, 'ID', df['ID'])\n",
    "output_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Format Your Predictions: \n",
    "\n",
    "Create a CSV file with the following columns:\n",
    "  - ID: Matches each test imageâ€™s unique identifier.\n",
    "  - LABEL: Your modelâ€™s predicted class label (an integer between 0 and 99) for each image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ensure Correct Format: \n",
    "\n",
    "Verify that your CSV file adheres strictly to the required format to prevent submission errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Submit for Evaluation: Upload your correctly formatted CSV file for assessment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
